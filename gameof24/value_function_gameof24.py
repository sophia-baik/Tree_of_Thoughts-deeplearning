# -*- coding: utf-8 -*-
"""game_of_24_value_function.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cVV8nJmv8L6oV0ej-5Hmm-UBXqrqVDIb

Goal: Find value function 0 <= V(y) <= 1 where V(y) is the estimated probability
that we will reach the goal (24) from state y

We want to create a dataset of partial states with values:
*  0 (can't reach 24)
*  1 (can reach 24)

MLP expects fixed sized input so we pad our feature space with zeroes, maybe append max/mean as additional features

Loss: binary cross entropy
"""

import random
import itertools
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import pandas as pd
import ast
from typing import List

data_path = "gameof24/24game_problems.csv"

df = pd.read_csv(data_path)
game_of_24_quads = [ast.literal_eval(x) for x in df['numbers']]

def simulate_paths(quad, max_depth = 3):
  visited = set()
  success = set()

  def dfs(state, depth, path):
    # sorted ensures that states are order agnostic and we aren't learning different
    # weights for states that are logically the same
    state = sorted(float(x) for x in state)

    if tuple(state) in visited:
      return
    visited.add(tuple(state))
    path.append(state)

    if len(state) == 1:
      # if we're using floats we need to allow some wiggle room
      if abs(state[0] - 24) < 1e-6:
        # mark parents as success (this is why we're doing dfs not bfs)
        for s in path:
          success.add((tuple(s), True))
        return

    if depth == 0:
      success.add((tuple(state), False))
      return

    # get all pairs of numbers
    for (i, j) in itertools.combinations(range(len(state)), 2):
      a, b = state[i], state[j]

      candidates = []
      candidates.append(a + b)
      candidates.append(a - b)
      candidates.append(b - a)
      candidates.append(a * b)
      if a != 0:
        candidates.append(b / a)
      if b != 0:
        candidates.append(a / b)

      for new_num in candidates:
        new_state = [state[k] for k in range(len(state)) if k != i and k != j] + [new_num]
        dfs(new_state, depth-1, path)

  dfs(quad, max_depth,[])
  return success

def generate_training_data(data, max_depth = 3):
  X = []
  Y = []

  for quad in data:
    reachable_states = simulate_paths(quad, max_depth)
    for state, value in reachable_states:
      X.append(pad(state))
      Y.append(int(value))
  return X, Y

def pad(state):
  state = list(state)
  return [0] * (4 - len(state)) + state

class ValueNetwork(nn.Module):
  def __init__(self):
      super(ValueNetwork, self).__init__()
      self.fc1 = nn.Linear(17, 128)
      self.bn1 = nn.BatchNorm1d(128)
      self.dropout1 = nn.Dropout(0.3)

      self.fc2 = nn.Linear(128, 128)
      self.bn2 = nn.BatchNorm1d(128)
      self.dropout2 = nn.Dropout(0.3)

      self.fc3 = nn.Linear(128, 64)
      self.bn3 = nn.BatchNorm1d(64)
      
      self.fc4 = nn.Linear(64, 1)

  def forward(self, x):
      quad = x[:,:4]
      features = self.extract_features(quad)

      x = torch.cat([quad,features], dim = 1)

      x = F.relu(self.bn1(self.fc1(x)))
      x = self.dropout1(x)
      x = F.relu(self.bn2(self.fc2(x)))
      x = self.dropout2(x)
      x = F.relu(self.bn3(self.fc3(x)))
      x = torch.sigmoid(self.fc4(x))
      return x

def extract_features(quad: List[int]):
    features = []
    
    # Are there pairs that sum to nice values?
    for i in range(len(quad)):
        for j in range(i+1, len(quad)):
            sum = quad[i] + quad[j]
            product = quad[i] * quad[j]
            features.append(1 if sum in [12, 24, 8, 6] else 0)
            features.append(1 if product in [12, 24, 8, 6] else 0)
    
    # Are there factors of 24?
    features.append(1 if any(n in [2, 3, 4, 6, 8, 12] for n in quad) else 0)
    
    return features

def train_value_network(X_train, y_train, epochs=10, batch_size=32):
    model = ValueNetwork()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    loss_fn = nn.BCELoss()

    X_train = torch.tensor(X_train, dtype=torch.float32)
    y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)

    for epoch in range(epochs):
      total_loss = 0
      correct = 0
      # create a random permutation of the data then create batches
      perm = torch.randperm(len(X_train))
      for i in range(0, len(X_train), batch_size):
          idx = perm[i:i+batch_size]
          batch_x = X_train[idx]
          batch_y = y_train[idx]

          optimizer.zero_grad()
          preds = model(batch_x)
          loss = loss_fn(preds, batch_y)
          loss.backward()
          optimizer.step()

          total_loss += loss.item() * batch_x.size(0)
          pred_labels = (preds > 0.5).float()
          correct += (pred_labels == batch_y).sum().item()

      avg_loss = total_loss / len(X_train)
      accuracy = correct / len(X_train)
      print(f"Epoch {epoch+1}: Loss = {avg_loss:.4f}, Accuracy = {accuracy:.4f}")

    return model

if __name__ == "__main__":
    df = pd.read_csv("gameof24/24game_problems.csv")
    game_of_24_quads = [ast.literal_eval(x) for x in df['numbers']]

    States, Values = generate_training_data(game_of_24_quads)
    model = train_value_network(States, Values, epochs=10, batch_size=32)
    torch.save(model.state_dict(), 'value_network.pth')